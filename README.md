#  summary-project-Muezzin
## There is still room for improvement....ðŸ˜œ

---

## Project Structure

```
summary-project-Muazzin/
â”œâ”€â”€ metadata-handling/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚    â”œâ”€â”€ main.py.py
â”‚   â”‚    â”œâ”€â”€ manager.py
â”‚   â”‚    â”œâ”€â”€ dict_builder.py
â”‚   â”‚    â””â”€â”€ metadata_retrieval.py
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ database-distribution/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ manager.py
â”‚   â”‚   â”œâ”€â”€ create_unique_id.py
â”‚   â”‚   â””â”€â”€ wav_to_binary.py
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ audio-transcription/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ manager.py
â”‚   â”‚   â”œâ”€â”€ binary_to-wav.py
â”‚   â”‚   â”œâ”€â”€ temp_audio.wav
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ text_classification/
â”‚   â”œâ”€â”€ deciphering.py
â”‚   â”œâ”€â”€ identifying_matches.py
â”‚   â”œâ”€â”€ level_attach.py
â”‚   â”œâ”€â”€ manager.py
â”‚   â”œâ”€â”€ percentage_calculation.py
â”‚   â””â”€â”€ words_lists
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ publisher.py
â”‚   â”œâ”€â”€ consumer.py
â”‚   â”œâ”€â”€ class logger.py
â”‚   â””â”€â”€ mongo_connector.wav
â”œâ”€â”€ config/
â”‚   â””â”€â”€ environments.py 
â”œâ”€â”€ docker-compose.yaml
â””â”€â”€ README.md
```

---

## Project Flow

1. The program uploads WAV files - podcasts to the system and sends them to Kafka as Jason with the path and metadata.
2. The following program listens to the specific topic in Kafka and extracts the information and generates a unique identifier based on the data, and publishes the metadata to Elastic and the binary file itself to Mongo, while simultaneously publishing the unique identifier to a different topic.
3. In the next step, the system listens to the topic and for each unique identifier that is published, the system retrieves the binary file from Mongo DB and transcribes the file and runs an identification against the lists of hostile words and assigns them risk percentages and a level of danger and updates all the data in Elastic according to the unique identifier.
4. The next step I was supposed to do was containerize everything and run it non-locally.
---

## Decisions

- I decided to do the transcription logic only after saving in Mongo
and perform a retrieval from Mongo and transcription,
and then update the elastic
The main reason is that transcription takes time and in large databases this is significant, so I will first send the metadata and only then update the transcription.
- My calculation of the risk percentage is based on the score obtained by dividing the text width by one hundred to increase the number (I didn't have time to adjust the calculation to be more accurate).
- The decision on the levels of danger was made based on a visual examination of the statistics and without in-depth thought due to lack of time.
---


## Tech Stack

- Python 3.10+
- ElasticSearch
- Mongo DB
- Kafka
- Kibana
- SpeechRecognition
---

## Contact

Project maintained by **Shlomo Wind**  
Feel free to fork, improve, and use in your own systems.